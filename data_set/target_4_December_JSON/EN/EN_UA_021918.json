{
    "text": "US, China, Israel and others are developing AI killer drones; this poses significant risks \n\n by Rhoda Wilson, Expose News:\n\nThe Pentagon\u2019s recent developments in AI technology have drawn concern and criticism as they approach the deployment of autonomous AI weapons systems capable of making lethal decisions independently.\n\nThe New York Times reports that countries such as the United States, China and Israel are actively working on lethal autonomous weapons empowered by artificial intelligence (\u201cAI\u201d), which can autonomously identify and engage targets.\n\nTRUTH LIVES on at https://sgtreport.tv/\n\nCritics argue that the use of AI-controlled drones with the ability to autonomously kill humans is a highly alarming development, as it places life-or-death choices on machines with minimal human oversight. Several countries, including Russia, Australia and Israel are opposing efforts by other nations to pass a binding resolution at the United Nations calling for a ban on AI killer drones.\n\nThe issue surrounding the deployment of AI weapons has sparked intense debate, with key questions revolving around the role of human agency in the use of force. Austria\u2019s chief negotiator on the matter, Alexander Kmentt, emphasised that this issue is not just a security and legal concern but also an ethical one.\n\nMeanwhile, the Pentagon has revealed plans to deploy swarms of AI-enabled drones as part of their AI weapons programme. These drones, equipped with advanced AI capabilities, are intended to provide the United States with a tactical advantage, countering the numerical superiority of China\u2019s Liberation Army.\n\nUS Deputy Secretary of Defence Kathleen Hicks further highlighted the role of AI-controlled drone swarms in reshaping battlefield dynamics, making them harder to plan against, hit and defeat. However, concerns arise regarding human supervision and decision-making capabilities, as some argue that limitations on AI\u2019s autonomy could hinder strategic advantages.\n\nCritics also point to recent incidents where AI drones have been utilised in conflict zones, such as Ukraine\u2019s use of AI-controlled drones during its conflict with Russia. The extent of human casualties caused by these AI drones remains uncertain, raising additional concerns.\n\nAdvocacy groups like the Campaign to Stop Killer Robots warn that AI technology\u2019s dehumanisation poses significant risks. This dehumanisation could not only impact the use of force but also permeate other aspects of our lives, extending to automation in law enforcement, smart homes, and beyond. The campaign notes the urgent need for a global treaty banning autonomous weapons to prevent the wide-scale production and proliferation of these technologies from potentially falling into the wrong hands.",
    "article_id": "EN_UA_021918.txt",
    "category": "Other",
    "narratives": [
        "Other"
    ],
    "subnarratives": [
        "Other"
    ]
}